# -*- coding: utf-8 -*-
"""Copy of Animal Health Classification.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SErOGaXz5GAEmyBnDiMbRyxX4-YJjr8e
"""

import pandas as pd
df = pd.read_csv("animal_health.csv")
df.head()

# Shape of dataset (rows, columns)
print("Shape of dataset:", df.shape)

# List all column names
print("\nColumn names:", df.columns.tolist())

# Basic info: data types and missing values
df.info()

# Summary statistics
df.describe(include='all')

df.nunique()

'''
Milestone 2 : This is the preparation of my dataset .Now we will clean and prepare
my dataset.
'''
df.isnull().sum()

#Encode data into numbers
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

# Encode all columns except the target for now
for col in ['AnimalName', 'symptoms1', 'symptoms2', 'symptoms3', 'symptoms4', 'symptoms5']:
    df[col] = le.fit_transform(df[col])

# Convert target: Yes ‚Üí 1, No ‚Üí 0
df['Dangerous'] = df['Dangerous'].map({'Yes': 1, 'No': 0})

df.head()

#Split the data
from sklearn.model_selection import train_test_split

# Separate features and target
X = df.drop('Dangerous', axis=1)
y = df['Dangerous']

# Split into training and testing data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Training samples:", X_train.shape[0])
print("Testing samples:", X_test.shape[0])

# Drop any rows where 'Dangerous' is missing
df = df.dropna(subset=['Dangerous'])
print("Null values in 'Dangerous':", df['Dangerous'].isnull().sum())

# Split the data again
from sklearn.model_selection import train_test_split

X = df.drop('Dangerous', axis=1)
y = df['Dangerous']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the model again
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()
model.fit(X_train, y_train)

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Predict on the test set
y_pred = model.predict(X_test)

# Accuracy
accuracy = accuracy_score(y_test, y_pred)
print("‚úÖ Accuracy:", round(accuracy * 100, 2), "%")

# Classification Report
print("\nüìã Classification Report:")
print(classification_report(y_test, y_pred))

# Confusion Matrix
print("\nüîç Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

import matplotlib.pyplot as plt

# Visualizing Dangerous class balance
df['Dangerous'].value_counts().plot(kind='pie', autopct='%1.1f%%', colors=['skyblue', 'salmon'], startangle=90)
plt.title("Animal Danger Status Distribution")
plt.ylabel('')
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Feature importance
importances = model.feature_importances_
feature_names = X_train.columns
importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})
importance_df = importance_df.sort_values(by='Importance', ascending=False)

# Plot
plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')
plt.title('üí° Which Symptoms Influence Prediction Most?')
plt.xlabel('Importance Score')
plt.ylabel('Symptom')
plt.show()

from IPython.display import Markdown as md
md_text = """
Project Summary

This project uses machine learning to help detect dangerous health conditions in animals based on symptom patterns.
With over 800 records and 5 key symptom columns, we built a *Random Forest Classifier* that reached *98.85% accuracy*.
Visuals such as pie charts and feature bars were added to make the data story more clear

---
"""
display(md(md_text))

def predict_danger(symptoms):
    symptoms = label_encoder.transform(symptoms)
    prediction = model.predict([symptoms])
    return 'Dangerous' if prediction[0] == 1 else 'Not Dangerous'

models = {
    "Logistic Regression": logreg,
    "Random Forest": rf,
    "Support Vector Machine": svm
}

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

#Train Logistic Regression
logreg = LogisticRegression()
logreg.fit(X_train, y_train)

# Train Random Forest
rf = RandomForestClassifier()
rf.fit(X_train, y_train)

# Train SVM
svm = SVC(probability=True)
svm.fit(X_train, y_train)

from sklearn.model_selection import train_test_split

import pandas as pd
df = pd.read_csv("animal_health.csv")
df.head()

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

# Make a copy of the dataset
df_encoded = df.copy()
label_encoder = LabelEncoder()

# Label encode all columns
for column in df_encoded.columns:
    df_encoded[column] = label_encoder.fit_transform(df_encoded[column])

# Features and label
X = df_encoded.drop("Dangerous", axis=1)
y = df_encoded["Dangerous"]

# Split into train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

# Train Logistic Regression
logreg = LogisticRegression()
logreg.fit(X_train, y_train)

# Train Random Forest
rf = RandomForestClassifier()
rf.fit(X_train, y_train)

# Train SVM
svm = SVC(probability=True)
svm.fit(X_train, y_train)

#evaluate the libraries
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve
import seaborn as sns
import matplotlib.pyplot as plt

#check the ACCURACY
models = {
    "Logistic Regression": logreg,
    "Random Forest": rf,
    "Support Vector Machine": svm
}

for name, model in models.items():
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"{name} - Accuracy: {accuracy:.2f}")

#Confusion Matrix
for name, model in models.items():
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f"{name} - Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

#ROC Curve
for name, model in models.items():
    if hasattr(model, "predict_proba"):  # check if model supports probabilities
        y_proba = model.predict_proba(X_test)[:, 1]
        fpr, tpr, _ = roc_curve(y_test, y_proba)
        auc_score = roc_auc_score(y_test, y_proba)
        plt.plot(fpr, tpr, label=f"{name} (AUC = {auc_score:.2f})")

plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - All Models")
plt.legend()
plt.show()

# First, install joblib if not already
!pip install joblib

import joblib

# Save the best model
joblib.dump(rf, "best_animal_health_model.pkl")

# Load the model later
loaded_model = joblib.load("best_animal_health_model.pkl")

#Test the loaded model
y_pred_loaded = loaded_model.predict(X_test)

# Recheck performance
from sklearn.metrics import accuracy_score
print("Accuracy of loaded model:", accuracy_score(y_test, y_pred_loaded))

import joblib
joblib.dump(svm,"best_model.pkl")

from google.colab import files
files.download("best_model.pkl")